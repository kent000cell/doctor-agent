"""AI Doctor Agent - Main API Server

Agent Skills ìŠ¤í™ ê¸°ë°˜ ì˜ë£Œ AI ì—ì´ì „íŠ¸
"""

import json
import asyncio
import sys
from pathlib import Path
from typing import AsyncGenerator

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from pydantic import BaseModel
from openai import OpenAI, OpenAIError

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).parent.parent
sys.path.insert(0, str(BASE_DIR))

from backend.config import config
from backend.skill_loader import SkillLoader
from backend.tools.registry import ToolRegistry
from backend.tools.definitions import TOOL_DEFINITIONS
from backend.logger import get_logger
from data import MockDataSource

# ë¡œê±° ì„¤ì •
logger = get_logger("main")


# === ì´ˆê¸°í™” ===

app = FastAPI(
    title="AI Doctor Agent API",
    description="Agent Skills ê¸°ë°˜ AI ì˜ë£Œ ë³´ì¡° ì—ì´ì „íŠ¸",
    version="1.0.0",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# === ì—ëŸ¬ í•¸ë“¤ëŸ¬ ===

@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """HTTP ì˜ˆì™¸ í•¸ë“¤ëŸ¬"""
    logger.warning(f"HTTP {exc.status_code}: {exc.detail} | Path: {request.url.path}")
    return JSONResponse(
        status_code=exc.status_code,
        content={"error": exc.detail, "status_code": exc.status_code}
    )


@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """ì¼ë°˜ ì˜ˆì™¸ í•¸ë“¤ëŸ¬"""
    logger.error(f"Unhandled exception: {str(exc)} | Path: {request.url.path}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={"error": "Internal server error", "detail": str(exc)}
    )


# ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
try:
    logger.info("Initializing AI Doctor Agent...")
    skill_loader = SkillLoader(config.skills_dir)
    logger.info(f"Loaded {len(skill_loader.skills)} skills")

    data_source = MockDataSource()
    logger.info("Mock data source initialized")

    tool_registry = ToolRegistry(data_source, skill_loader)
    logger.info("Tool registry initialized")

    openai_client = OpenAI(api_key=config.openai_api_key)
    logger.info(f"OpenAI client initialized (model: {config.openai_model})")
except Exception as e:
    logger.critical(f"Failed to initialize application: {str(e)}", exc_info=True)
    raise


# === í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ===

def load_prompt_template(name: str) -> str:
    """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ"""
    prompt_path = config.prompts_dir / f"{name}.md"
    if prompt_path.exists():
        return prompt_path.read_text(encoding="utf-8")
    raise FileNotFoundError(f"í”„ë¡¬í”„íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {name}")


def create_system_prompt() -> str:
    """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± (í…œí”Œë¦¿ + ìŠ¤í‚¬ XML ì£¼ì…)"""
    template = load_prompt_template("system")
    available_skills_xml = skill_loader.generate_available_skills_xml()
    return template.replace("{{available_skills}}", available_skills_xml)


# === ìš”ì²­/ì‘ë‹µ ëª¨ë¸ ===

class ChatRequest(BaseModel):
    message: str
    patient_id: str = "P001"
    image: str | None = None  # Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ (data:image/...;base64,...)


# === ì±„íŒ… ì²˜ë¦¬ ===

def build_user_content(message: str, patient_id: str, image: str | None = None) -> list | str:
    """ì‚¬ìš©ì ë©”ì‹œì§€ ì»¨í…ì¸  ìƒì„± (í…ìŠ¤íŠ¸ ë˜ëŠ” ë©€í‹°ëª¨ë‹¬)"""
    user_text = f"[í™˜ì ID: {patient_id}]\n\n{message}"

    if not image:
        return user_text

    # ë©€í‹°ëª¨ë‹¬ ì»¨í…ì¸  (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€)
    content = [
        {"type": "text", "text": user_text + "\n\n[ì²¨ë¶€ëœ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. í”¼ë¶€ ìƒíƒœ, ìƒì²˜, ë°œì§„ ë“± ì˜ë£Œì ìœ¼ë¡œ ê´€ì°°ë˜ëŠ” ì†Œê²¬ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.]"}
    ]

    # Base64 ì´ë¯¸ì§€ ì¶”ê°€
    if image.startswith("data:"):
        content.append({
            "type": "image_url",
            "image_url": {"url": image}
        })
    else:
        # data: í”„ë¦¬í”½ìŠ¤ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
        content.append({
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{image}"}
        })

    return content


async def process_chat(message: str, patient_id: str = "P001", image: str | None = None) -> AsyncGenerator[str, None]:
    """ì±„íŒ… ì²˜ë¦¬ - SSE ìŠ¤íŠ¸ë¦¬ë°

    Agent Skills ìŠ¤í™ì— ë”°ë¥¸ ë™ì‘:
    1. Discovery: ì‹œì‘ ì‹œ ìŠ¤í‚¬ ë©”íƒ€ë°ì´í„°ê°€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ë¨
    2. Activation: LLMì´ read_skill ë„êµ¬ë¡œ í•„ìš”í•œ ìŠ¤í‚¬ì˜ ì „ì²´ ë‚´ìš©ì„ ë¡œë“œ
    3. Execution: LLMì´ ìŠ¤í‚¬ ì§€ì¹¨ì— ë”°ë¼ ë„êµ¬ë“¤ì„ ì‹¤í–‰
    """

    # ì‚¬ìš©ì ë©”ì‹œì§€ ìƒì„± (ì´ë¯¸ì§€ í¬í•¨ ê°€ëŠ¥)
    user_content = build_user_content(message, patient_id, image)

    messages = [
        {"role": "system", "content": create_system_prompt()},
        {"role": "user", "content": user_content}
    ]

    # === 1ë‹¨ê³„: Discovery ===
    yield _log_event(
        "discovery",
        "ğŸ¥ AI Doctor Agent ì‹œì‘",
        description="ìŠ¤í‚¬ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ"
    )
    await asyncio.sleep(0.1)

    skill_names = [s["name"] for s in skill_loader.list_skills()]
    yield _log_event(
        "skills_loaded",
        f"ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¤í‚¬: {skill_names}",
        description="ì§„ë‹¨ ë° ì¹˜ë£Œ ìŠ¤í‚¬ ì¤€ë¹„ë¨"
    )
    await asyncio.sleep(0.1)

    # ì´ë¯¸ì§€ ì²¨ë¶€ ì—¬ë¶€ì— ë”°ë¥¸ ë¡œê·¸
    if image:
        yield _log_event(
            "start",
            f"ğŸ“· ì´ë¯¸ì§€ ì²¨ë¶€ë¨ - {message[:30]}...",
            description="ì´ë¯¸ì§€ + ì¦ìƒ ë¶„ì„ ì‹œì‘"
        )
    else:
        yield _log_event(
            "start",
            f"í™˜ì ì¦ìƒ ì ‘ìˆ˜: {message[:50]}...",
            description="ì¦ìƒ ë¶„ì„ ì‹œì‘"
        )
    await asyncio.sleep(0.1)

    # === 2ë‹¨ê³„: ì—ì´ì „íŠ¸ ë£¨í”„ ===
    max_iterations = 10
    for iteration in range(1, max_iterations + 1):
        yield _log_event(
            "llm_thinking",
            f"[ì§„ë‹¨ ë‹¨ê³„ #{iteration}] ë¶„ì„ ì¤‘...",
            description="AIê°€ ì¦ìƒì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤"
        )
        await asyncio.sleep(0.1)

        # OpenAI API í˜¸ì¶œ
        try:
            response = openai_client.chat.completions.create(
                model=config.openai_model,
                messages=messages,
                tools=TOOL_DEFINITIONS,
                tool_choice="auto",
            )
            logger.debug(f"OpenAI API response received (iteration {iteration})")
        except OpenAIError as e:
            error_msg = f"OpenAI API ì˜¤ë¥˜: {str(e)}"
            logger.error(error_msg, exc_info=True)
            yield _log_event("error", error_msg)
            yield _response_event(f"ì£„ì†¡í•©ë‹ˆë‹¤. AI ì„œë¹„ìŠ¤ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            break
        except Exception as e:
            error_msg = f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"
            logger.error(error_msg, exc_info=True)
            yield _log_event("error", error_msg)
            yield _response_event(f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            break

        choice = response.choices[0]
        assistant_message = choice.message

        # ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬
        if assistant_message.tool_calls:
            messages.append(assistant_message)

            for tool_call in assistant_message.tool_calls:
                tool_name = tool_call.function.name
                tool_args = json.loads(tool_call.function.arguments)

                # ë„êµ¬ ìœ í˜•ì— ë”°ë¥¸ ë¡œê·¸
                if tool_name == "read_skill":
                    yield _log_event(
                        "activation",
                        f"ğŸ“š ìŠ¤í‚¬ ë¡œë“œ: {tool_args.get('skill_name')}",
                        description="ì§„ë‹¨/ì¹˜ë£Œ ê°€ì´ë“œë¼ì¸ í™•ì¸ ì¤‘",
                        tool=tool_name,
                        args=tool_args
                    )
                elif tool_name.startswith("analyze"):
                    emoji = "ğŸ”¬" if "xray" in tool_name or "mri" in tool_name or "ct" in tool_name else "ğŸ©º"
                    yield _log_event(
                        "tool_call",
                        f"{emoji} ë¶„ì„ ë„êµ¬ ì‹¤í–‰: {tool_name}",
                        description="ì˜ë£Œ ë°ì´í„° ë¶„ì„ ì¤‘",
                        tool=tool_name,
                        args=tool_args
                    )
                elif tool_name == "assess_severity":
                    yield _log_event(
                        "tool_call",
                        f"âš–ï¸ ì‹¬ê°ë„ í‰ê°€ ì¤‘",
                        description="ì§ˆë³‘ ì§„í–‰ ë‹¨ê³„ íŒë‹¨",
                        tool=tool_name,
                        args=tool_args
                    )
                elif tool_name == "recommend_treatment":
                    yield _log_event(
                        "tool_call",
                        f"ğŸ’Š ì¹˜ë£Œë²• ê²€ìƒ‰ ì¤‘",
                        description="ìµœì ì˜ ì¹˜ë£Œ ì˜µì…˜ íƒìƒ‰",
                        tool=tool_name,
                        args=tool_args
                    )
                else:
                    yield _log_event(
                        "tool_call",
                        f"ğŸ”§ ë„êµ¬ ì‹¤í–‰: {tool_name}",
                        tool=tool_name,
                        args=tool_args
                    )
                await asyncio.sleep(0.1)

                # ë„êµ¬ ì‹¤í–‰
                try:
                    logger.info(f"Executing tool: {tool_name} with args: {tool_args}")
                    tool_result = tool_registry.execute(tool_name, tool_args)
                    logger.debug(f"Tool {tool_name} executed successfully")

                    yield _log_event(
                        "tool_result",
                        f"âœ… {tool_name} ì™„ë£Œ",
                        tool=tool_name,
                        result=tool_result[:300] if len(tool_result) > 300 else tool_result
                    )
                except Exception as e:
                    error_msg = f"ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜ ({tool_name}): {str(e)}"
                    logger.error(error_msg, exc_info=True)
                    tool_result = json.dumps({"error": error_msg}, ensure_ascii=False)
                    yield _log_event("error", error_msg)

                await asyncio.sleep(0.1)

                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": tool_result
                })

        # ìµœì¢… ì‘ë‹µ
        else:
            yield _log_event(
                "complete",
                "ğŸ“‹ ì§„ë‹¨ ë° ì¹˜ë£Œ ì¶”ì²œ ì™„ë£Œ",
                description="AI ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"
            )
            yield _response_event(assistant_message.content)
            break


def _log_event(step: str, message: str, **extra) -> str:
    """ë¡œê·¸ ì´ë²¤íŠ¸ ìƒì„±"""
    data = {"step": step, "message": message, **extra}
    return json.dumps({"type": "log", "data": data}, ensure_ascii=False) + "\n"


def _response_event(content: str) -> str:
    """ì‘ë‹µ ì´ë²¤íŠ¸ ìƒì„±"""
    return json.dumps({"type": "response", "data": {"content": content}}, ensure_ascii=False) + "\n"


# === API ì—”ë“œí¬ì¸íŠ¸ ===

@app.get("/api/skills")
async def get_skills():
    """ìŠ¤í‚¬ ëª©ë¡ ë°˜í™˜"""
    try:
        logger.info("Fetching skills list")
        return {
            "skills": skill_loader.list_skills(),
            "xml": skill_loader.generate_available_skills_xml(),
        }
    except Exception as e:
        logger.error(f"Failed to fetch skills: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail="Failed to fetch skills")


@app.post("/api/chat")
async def chat(request: ChatRequest):
    """ì±„íŒ… API - SSE ìŠ¤íŠ¸ë¦¬ë° (ì´ë¯¸ì§€ ì²¨ë¶€ ì§€ì›)"""
    try:
        logger.info(f"Chat request received | patient_id: {request.patient_id} | message: {request.message[:50]}...")
        if request.image:
            logger.info("Image attached to request")

        return StreamingResponse(
            process_chat(request.message, request.patient_id, request.image),
            media_type="text/event-stream"
        )
    except Exception as e:
        logger.error(f"Chat processing failed: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail="Chat processing failed")


@app.get("/api/health")
async def health():
    """í—¬ìŠ¤ì²´í¬"""
    try:
        return {
            "status": "ok",
            "agent": "AI Doctor Agent",
            "skills_count": len(skill_loader.skills),
            "model": config.openai_model,
        }
    except Exception as e:
        logger.error(f"Health check failed: {str(e)}", exc_info=True)
        return {
            "status": "error",
            "error": str(e)
        }


# === ì§ì ‘ ì‹¤í–‰ ===

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host=config.host, port=config.port)
